{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24712 20\n"
     ]
    }
   ],
   "source": [
    "# Data Processing\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, normalize, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "train_data = np.genfromtxt('trainData.csv', delimiter=',', dtype=str)\n",
    "m = train_data.shape[0] - 1\n",
    "d = train_data.shape[1]\n",
    "print(m, d)\n",
    "train_input_raw, train_output = train_data[1:,0:d-1].tolist(), train_data[1:,d-1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above step uses `numpy`'s `genfromtxt` function since there are no missing values. Below I randomly print to get the actual types of data like textual information and specific fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['28', '\"admin.\"', '\"single\"', '\"university.degree\"', '\"no\"', '\"yes\"', '\"no\"', '\"cellular\"', '\"aug\"', '\"mon\"', '1', '999', '0', '\"nonexistent\"', '-2.9', '92.201', '-31.4', '0.861', '5076.2'], '1']\n"
     ]
    }
   ],
   "source": [
    "print([train_input_raw[0], train_output[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing step 1: \n",
    "Remove quotes in textual information\n",
    "\n",
    "#### Preprocessing step 2:\n",
    "Convert numeric information to numbers as opposed to within single quotes. These fields are `0, 10, 11, 12, 14, ..., 19`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.0, 'admin.', 'single', 'university.degree', 'no', 'yes', 'no', 'cellular', 'aug', 'mon', 1.0, 999.0, 0.0, 'nonexistent', -2.9, 92.201, -31.4, 0.861, 5076.2]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, m-1):\n",
    "    for j in range(0, d-1):\n",
    "        if train_input_raw[i][j].find(\"\\\"\") != -1:\n",
    "            train_input_raw[i][j] = train_input_raw[i][j][1:-1] # removing double quotes in pairs\n",
    "        else:\n",
    "            train_input_raw[i][j] = float(train_input_raw[i][j])\n",
    "    train_output[i] = float(train_output[i])\n",
    "train_output = np.array(train_output).astype(float)\n",
    "\n",
    "print(train_input_raw[0])\n",
    "print(train_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the preprocessing has been completed, it is time to separate the input and outputs and begin training. Clearly, we might have to go with Ensemble methods since the data has both textual and numeric information in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50.0, 'blue-collar', 'married', 'basic.4y', 'no', 'yes', 'no', 'cellular', 'jul', 'mon', 2.0, 999.0, 0.0, 'nonexistent', 1.4, 93.918, -42.7, 4.962, 5228.1]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "rand_index = np.random.randint(low=0, high=m)\n",
    "print(train_input_raw[rand_index])\n",
    "print(train_output[rand_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the data through a simple level of preprocessing, I am going to convert text data into numeric values. For this I am first going to tokenize and then merge this into the actual training input.\n",
    "\n",
    "#### Preprocessing step 3:\n",
    "Convert the text data into numbers using `LabelEncoder`.\n",
    "\n",
    "#### Preprocessing step 4:\n",
    "Normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training text data : (24712, 10)\n",
      "Size of training text data: (24712, 10)\n",
      "Text: ['admin.' 'single' 'university.degree' 'no' 'yes' 'no' 'cellular' 'aug'\n",
      " 'mon' 'nonexistent'] --> Data: [1 3 7 1 3 1 1 2 2 2]\n",
      "Text: ['blue-collar' 'single' 'basic.9y' 'no' 'yes' 'no' 'cellular' 'jul' 'tue'\n",
      " 'nonexistent'] --> Data: [2 3 3 1 3 1 1 4 4 2]\n"
     ]
    }
   ],
   "source": [
    "train_text_data = np.hstack((np.array(train_input_raw)[:,1:10], np.array(train_input_raw)[:,13:14]))\n",
    "print('Size of training text data : {0}'.format(train_text_data.shape))\n",
    "\n",
    "# Converting the textual data into one vector per training input\n",
    "train_text_vectors = []\n",
    "\n",
    "for j in range(0, train_text_data.shape[1]):\n",
    "    lbl_enc = LabelEncoder()\n",
    "    train_text_vectors.append(lbl_enc.fit_transform(train_text_data[:,j]))\n",
    "train_text_vectors = np.array(train_text_vectors).T\n",
    "\n",
    "print('Size of training text data: {0}'.format(train_text_vectors.shape))\n",
    "print('Text: {0} --> Data: {1}'.format(train_text_data[0], train_text_vectors[0]))\n",
    "print('Text: {0} --> Data: {1}'.format(train_text_data[10], train_text_vectors[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24712, 19)\n",
      "Vector = [-1.1518788  -1.04245572  1.36067936  1.05600834 -0.51164653  0.94134947\n",
      " -0.44949276 -0.75723938 -1.38470179 -0.70956021 -0.56425354  0.19653049\n",
      " -0.35249416  0.19500115 -1.90310477 -2.38261316  1.97762226 -1.5909553\n",
      " -1.25826956]: \n",
      "Norm = 5.250495168763574\n",
      "(24712, 19)\n",
      "Vector = [-0.21938479 -0.19854427  0.25915258  0.20112548 -0.09744729  0.17928775\n",
      " -0.08560959 -0.14422247 -0.26372785 -0.13514158 -0.10746673  0.03743085\n",
      " -0.06713541  0.03713957 -0.36246196 -0.45378828  0.37665443 -0.30301052\n",
      " -0.23964779]: \n",
      "Norm = 1.0\n"
     ]
    }
   ],
   "source": [
    "train_input = np.hstack((np.array(train_input_raw)[:,0:1], \n",
    "                         train_text_vectors[:,0:train_text_vectors.shape[1] - 1], \n",
    "                         np.array(train_input_raw)[:,10:13],\n",
    "                         train_text_vectors[:,train_text_vectors.shape[1] - 1].reshape(-1, 1),\n",
    "                         np.array(train_input_raw)[:,14:]\n",
    "                        )).astype(float)\n",
    "mean_reduce = StandardScaler()\n",
    "train_input = mean_reduce.fit_transform(train_input)\n",
    "print(train_input.shape)\n",
    "print('Vector = {0}: \\nNorm = {1}'.format(train_input[0], np.linalg.norm(train_input[0])))\n",
    "\n",
    "train_input = normalize(train_input)\n",
    "print(train_input.shape)\n",
    "print('Vector = {0}: \\nNorm = {1}'.format(train_input[0], np.linalg.norm(train_input[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the preprocessing steps are completed. I will try my preprocessed dataset on multiple methods of classification.\n",
    "For this, I will generate 10 folds (stratified) and use 10-fold cross validation to get the best method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\tTrain number: 22240 Validation number: 2472\n",
      "Fold 2\tTrain number: 22240 Validation number: 2472\n",
      "Fold 3\tTrain number: 22240 Validation number: 2472\n",
      "Fold 4\tTrain number: 22240 Validation number: 2472\n",
      "Fold 5\tTrain number: 22241 Validation number: 2471\n",
      "Fold 6\tTrain number: 22241 Validation number: 2471\n",
      "Fold 7\tTrain number: 22241 Validation number: 2471\n",
      "Fold 8\tTrain number: 22241 Validation number: 2471\n",
      "Fold 9\tTrain number: 22242 Validation number: 2470\n",
      "Fold 10\tTrain number: 22242 Validation number: 2470\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10)\n",
    "folds = []\n",
    "for tr_split, va_split in skf.split(train_input, train_output):\n",
    "    folds.append((tr_split, va_split))\n",
    "for i in range(0, len(folds)):\n",
    "    print(\"Fold {0}\\tTrain number: {1} Validation number: {2}\".format(i+1, len(folds[i][0]), len(folds[i][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1: SVM with Gaussian Kernel with 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing fold 1\n",
      "Performing fold 2\n",
      "Performing fold 3\n",
      "Performing fold 4\n",
      "Performing fold 5\n",
      "Performing fold 6\n",
      "Performing fold 7\n",
      "Performing fold 8\n",
      "Performing fold 9\n",
      "Performing fold 10\n",
      "Average training accuracy after 10 fold cross validation = 0.8958805422110278\n",
      "Average training precision after 10 fold cross validation = 0.6147864168325933\n",
      "Average training recall after 10 fold cross validation = 0.20294533040861612\n",
      "Average validation accuracy after 10 fold cross validation = 0.8958804098640757\n",
      "Average validation precision after 10 fold cross validation = 0.6136531230006101\n",
      "Average validation recall after 10 fold cross validation = 0.20293958381681754\n"
     ]
    }
   ],
   "source": [
    "accu_train = prec_train = rcll_train = 0.0\n",
    "accu_valid = prec_valid = rcll_valid = 0.0\n",
    "g_svm = SVC(kernel='rbf', cache_size=2000)\n",
    "for i in range(0, len(folds)):\n",
    "    print(\"Performing fold {0}\".format(i+1))\n",
    "    g_svm.fit(train_input[folds[i][0]], train_output[folds[i][0]])\n",
    "\n",
    "    train_pred = g_svm.predict(train_input[folds[i][0]])\n",
    "    valid_pred = g_svm.predict(train_input[folds[i][1]])\n",
    "\n",
    "    accu_train += accuracy_score(train_output[folds[i][0]], train_pred)\n",
    "    prec_train += precision_score(train_output[folds[i][0]], train_pred)\n",
    "    rcll_train += recall_score(train_output[folds[i][0]], train_pred)\n",
    "    \n",
    "    accu_valid += accuracy_score(train_output[folds[i][1]], valid_pred)\n",
    "    prec_valid += precision_score(train_output[folds[i][1]], valid_pred)\n",
    "    rcll_valid += recall_score(train_output[folds[i][1]], valid_pred)\n",
    "    \n",
    "print(\"Average training accuracy after 10 fold cross validation = {0}\".format(accu_train/len(folds)))\n",
    "print(\"Average training precision after 10 fold cross validation = {0}\".format(prec_train/len(folds)))\n",
    "print(\"Average training recall after 10 fold cross validation = {0}\".format(rcll_train/len(folds)))\n",
    "\n",
    "print(\"Average validation accuracy after 10 fold cross validation = {0}\".format(accu_valid/len(folds)))\n",
    "print(\"Average validation precision after 10 fold cross validation = {0}\".format(prec_valid/len(folds)))\n",
    "print(\"Average validation recall after 10 fold cross validation = {0}\".format(rcll_valid/len(folds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2: Random Forests with multiple number of trees and 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training accuracy after 10 fold cross validation = 0.9696144194277926 for m = 3\n",
      "Average training precision after 10 fold cross validation = 0.910236470415929 for m = 3\n",
      "Average training recall after 10 fold cross validation = 0.8102257097935016 for m = 3\n",
      "Average validation accuracy after 10 fold cross validation = 0.8700222660028347 for m = 3\n",
      "Average validation precision after 10 fold cross validation = 0.3922256858740375 for m = 3\n",
      "Average validation recall after 10 fold cross validation = 0.2786918852015162 for m = 3\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9648438924490443 for m = 4\n",
      "Average training precision after 10 fold cross validation = 0.9642927636662406 for m = 4\n",
      "Average training recall after 10 fold cross validation = 0.7143998515339633 for m = 4\n",
      "Average validation accuracy after 10 fold cross validation = 0.8848742262438248 for m = 4\n",
      "Average validation precision after 10 fold cross validation = 0.4769901009550452 for m = 4\n",
      "Average validation recall after 10 fold cross validation = 0.20436038266161266 for m = 4\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9791059620102199 for m = 5\n",
      "Average training precision after 10 fold cross validation = 0.9523158947806211 for m = 5\n",
      "Average training recall after 10 fold cross validation = 0.857479486358488 for m = 5\n",
      "Average validation accuracy after 10 fold cross validation = 0.8795728758831537 for m = 5\n",
      "Average validation precision after 10 fold cross validation = 0.44651351813039586 for m = 5\n",
      "Average validation recall after 10 fold cross validation = 0.2869742915345143 for m = 5\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9741196503488609 for m = 6\n",
      "Average training precision after 10 fold cross validation = 0.9766022425943099 for m = 6\n",
      "Average training recall after 10 fold cross validation = 0.7891925964511519 for m = 6\n",
      "Average validation accuracy after 10 fold cross validation = 0.8859262355738288 for m = 6\n",
      "Average validation precision after 10 fold cross validation = 0.48685333472896675 for m = 6\n",
      "Average validation recall after 10 fold cross validation = 0.22268249916196076 for m = 6\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9833234387134338 for m = 7\n",
      "Average training precision after 10 fold cross validation = 0.9672772234302573 for m = 7\n",
      "Average training recall after 10 fold cross validation = 0.8818247463572456 for m = 7\n",
      "Average validation accuracy after 10 fold cross validation = 0.8840235656084804 for m = 7\n",
      "Average validation precision after 10 fold cross validation = 0.4742390398881179 for m = 7\n",
      "Average validation recall after 10 fold cross validation = 0.2790503081405843 for m = 7\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9793307748761911 for m = 8\n",
      "Average training precision after 10 fold cross validation = 0.9811601628902075 for m = 8\n",
      "Average training recall after 10 fold cross validation = 0.8325347708413979 for m = 8\n",
      "Average validation accuracy after 10 fold cross validation = 0.8887988949396426 for m = 8\n",
      "Average validation precision after 10 fold cross validation = 0.5140603456239827 for m = 8\n",
      "Average validation recall after 10 fold cross validation = 0.22305510430365386 for m = 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in range(3, 9):\n",
    "    rnd_frst = RandomForestClassifier(n_estimators = m)\n",
    "    accu_train = prec_train = rcll_train = 0.0\n",
    "    accu_valid = prec_valid = rcll_valid = 0.0\n",
    "    for i in range(0, len(folds)):\n",
    "        rnd_frst.fit(train_input[folds[i][0]], train_output[folds[i][0]])\n",
    "\n",
    "        train_pred = rnd_frst.predict(train_input[folds[i][0]])\n",
    "        valid_pred = rnd_frst.predict(train_input[folds[i][1]])\n",
    "\n",
    "        accu_train += accuracy_score(train_output[folds[i][0]], train_pred)\n",
    "        prec_train += precision_score(train_output[folds[i][0]], train_pred)\n",
    "        rcll_train += recall_score(train_output[folds[i][0]], train_pred)\n",
    "    \n",
    "        accu_valid += accuracy_score(train_output[folds[i][1]], valid_pred)\n",
    "        prec_valid += precision_score(train_output[folds[i][1]], valid_pred)\n",
    "        rcll_valid += recall_score(train_output[folds[i][1]], valid_pred)\n",
    "    \n",
    "    print(\"Average training accuracy after 10 fold cross validation = {0} for m = {1}\".format(accu_train/len(folds), m))\n",
    "    print(\"Average training precision after 10 fold cross validation = {0} for m = {1}\".format(prec_train/len(folds), m))\n",
    "    print(\"Average training recall after 10 fold cross validation = {0} for m = {1}\".format(rcll_train/len(folds), m))\n",
    "\n",
    "    print(\"Average validation accuracy after 10 fold cross validation = {0} for m = {1}\".format(accu_valid/len(folds), m))\n",
    "    print(\"Average validation precision after 10 fold cross validation = {0} for m = {1}\".format(prec_valid/len(folds), m))\n",
    "    print(\"Average validation recall after 10 fold cross validation = {0} for m = {1}\\n\".format(rcll_valid/len(folds), m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 3: AdaBoost with multiple weak classifiers and 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training accuracy after 10 fold cross validation = 0.8987311633843629 for t = 10\n",
      "Average training precision after 10 fold cross validation = 0.6810567932837791 for t = 10\n",
      "Average training recall after 10 fold cross validation = 0.19101281873603154 for t = 10\n",
      "Average validation accuracy after 10 fold cross validation = 0.8981063441803887 for t = 10\n",
      "Average validation precision after 10 fold cross validation = 0.6750924100207478 for t = 10\n",
      "Average validation recall after 10 fold cross validation = 0.18533689177690107 for t = 10\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.8987716245411631 for t = 25\n",
      "Average training precision after 10 fold cross validation = 0.6588623873064288 for t = 25\n",
      "Average training recall after 10 fold cross validation = 0.21120654142632533 for t = 25\n",
      "Average validation accuracy after 10 fold cross validation = 0.8979040951395874 for t = 25\n",
      "Average validation precision after 10 fold cross validation = 0.6489927663002939 for t = 25\n",
      "Average validation recall after 10 fold cross validation = 0.20654057399241896 for t = 25\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.8995584707852478 for t = 50\n",
      "Average training precision after 10 fold cross validation = 0.6696670907249589 for t = 50\n",
      "Average training recall after 10 fold cross validation = 0.21448047241510593 for t = 50\n",
      "Average validation accuracy after 10 fold cross validation = 0.8978229924973329 for t = 50\n",
      "Average validation precision after 10 fold cross validation = 0.6455760821620811 for t = 50\n",
      "Average validation recall after 10 fold cross validation = 0.20688739331115752 for t = 50\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9010692091854494 for t = 100\n",
      "Average training precision after 10 fold cross validation = 0.6781047378559512 for t = 100\n",
      "Average training recall after 10 fold cross validation = 0.23208053167408202 for t = 100\n",
      "Average validation accuracy after 10 fold cross validation = 0.8986727690781345 for t = 100\n",
      "Average validation precision after 10 fold cross validation = 0.6484974039766535 for t = 100\n",
      "Average validation recall after 10 fold cross validation = 0.22160594105360878 for t = 100\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9019954261282205 for t = 200\n",
      "Average training precision after 10 fold cross validation = 0.6800235811572412 for t = 200\n",
      "Average training recall after 10 fold cross validation = 0.24572959428310176 for t = 200\n",
      "Average validation accuracy after 10 fold cross validation = 0.8980255363378669 for t = 200\n",
      "Average validation precision after 10 fold cross validation = 0.6336665831379871 for t = 200\n",
      "Average validation recall after 10 fold cross validation = 0.2266303086563008 for t = 200\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9023326482577743 for t = 250\n",
      "Average training precision after 10 fold cross validation = 0.678989941396667 for t = 250\n",
      "Average training recall after 10 fold cross validation = 0.2523948591245283 for t = 250\n",
      "Average validation accuracy after 10 fold cross validation = 0.896932844856844 for t = 250\n",
      "Average validation precision after 10 fold cross validation = 0.614164747079992 for t = 250\n",
      "Average validation recall after 10 fold cross validation = 0.23058714318867488 for t = 250\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9040502185618475 for t = 500\n",
      "Average training precision after 10 fold cross validation = 0.687289541405323 for t = 500\n",
      "Average training recall after 10 fold cross validation = 0.27211076649573956 for t = 500\n",
      "Average validation accuracy after 10 fold cross validation = 0.8957590506275187 for t = 500\n",
      "Average validation precision after 10 fold cross validation = 0.5958222629167091 for t = 500\n",
      "Average validation recall after 10 fold cross validation = 0.23417137257935586 for t = 500\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.906392751264149 for t = 1000\n",
      "Average training precision after 10 fold cross validation = 0.7023665169240014 for t = 1000\n",
      "Average training recall after 10 fold cross validation = 0.29354187076764265 for t = 1000\n",
      "Average validation accuracy after 10 fold cross validation = 0.8951928713895887 for t = 1000\n",
      "Average validation precision after 10 fold cross validation = 0.5862914269530941 for t = 1000\n",
      "Average validation recall after 10 fold cross validation = 0.24279801964879705 for t = 1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in [10, 25, 50, 100, 200, 250, 500, 1000]:\n",
    "    rnd_frst = AdaBoostClassifier(n_estimators = t)\n",
    "    accu_train = prec_train = rcll_train = 0.0\n",
    "    accu_valid = prec_valid = rcll_valid = 0.0\n",
    "    for i in range(0, len(folds)):\n",
    "        rnd_frst.fit(train_input[folds[i][0]], train_output[folds[i][0]])\n",
    "\n",
    "        train_pred = rnd_frst.predict(train_input[folds[i][0]])\n",
    "        valid_pred = rnd_frst.predict(train_input[folds[i][1]])\n",
    "\n",
    "        accu_train += accuracy_score(train_output[folds[i][0]], train_pred)\n",
    "        prec_train += precision_score(train_output[folds[i][0]], train_pred)\n",
    "        rcll_train += recall_score(train_output[folds[i][0]], train_pred)\n",
    "    \n",
    "        accu_valid += accuracy_score(train_output[folds[i][1]], valid_pred)\n",
    "        prec_valid += precision_score(train_output[folds[i][1]], valid_pred)\n",
    "        rcll_valid += recall_score(train_output[folds[i][1]], valid_pred)\n",
    "    \n",
    "    print(\"Average training accuracy after 10 fold cross validation = {0} for t = {1}\".format(accu_train/len(folds), t))\n",
    "    print(\"Average training precision after 10 fold cross validation = {0} for t = {1}\".format(prec_train/len(folds), t))\n",
    "    print(\"Average training recall after 10 fold cross validation = {0} for t = {1}\".format(rcll_train/len(folds), t))\n",
    "\n",
    "    print(\"Average validation accuracy after 10 fold cross validation = {0} for t = {1}\".format(accu_valid/len(folds), t))\n",
    "    print(\"Average validation precision after 10 fold cross validation = {0} for t = {1}\".format(prec_valid/len(folds), t))\n",
    "    print(\"Average validation recall after 10 fold cross validation = {0} for t = {1}\\n\".format(rcll_valid/len(folds), t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it seems that we are randomly trying to use multiple classifiers. I believe that there is a fundamental problem in the preprocessing. I think we have to use the `OneHotEncoder` to encode categorical data after encoding using label as shown [here](http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.\n",
      "  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(train_text_vectors)\n",
    "train_text_ohe_vectors = ohe.transform(train_text_vectors).toarray()\n",
    "print(train_text_ohe_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24712, 72)\n",
      "Vector = [-1.1518788  -0.00636143  1.74069139 -0.54136613 -0.19193262 -0.1629241\n",
      " -0.27809875 -0.2094986  -0.19022619 -0.3265319  -0.14790156 -0.44416981\n",
      " -0.15868679 -0.08941353 -0.00636143 -0.35667631 -1.23783144  1.60282103\n",
      " -0.04271182 -0.00636143 -0.33630791 -0.24338659 -0.41762792 -0.5454267\n",
      " -0.02110275 -0.38186992  1.54561294 -0.20897184 -0.00636143  0.51196112\n",
      " -0.51183521 -0.00636143 -0.00636143 -0.90828189 -0.15530407  0.9524098\n",
      " -0.00636143  0.45871908 -0.15530407 -0.42049726 -0.00636143  0.75750396\n",
      " -0.75743781 -0.00636143 -0.26363944  2.37437524 -0.06686689 -0.46226923\n",
      " -0.38284321 -0.11544164 -0.70863102 -0.33038794 -0.12794206 -0.11916424\n",
      " -0.00636143 -0.48570462  1.93191265 -0.51366037 -0.49186773 -0.49091582\n",
      " -0.00636143 -0.34164991  0.40016662 -0.1860759  -0.56425354  0.19653049\n",
      " -0.35249416 -1.90310477 -2.38261316  1.97762226 -1.5909553  -1.25826956]: \n",
      "Norm = 6.788336172380378\n",
      "(24712, 72)\n",
      "Vector = [-0.169685   -0.00093711  0.25642386 -0.07974946 -0.02827388 -0.02400059\n",
      " -0.04096714 -0.03086155 -0.02802251 -0.0481019  -0.0217876  -0.06543132\n",
      " -0.02337639 -0.01317164 -0.00093711 -0.05254252 -0.18234681  0.23611397\n",
      " -0.00629194 -0.00093711 -0.04954202 -0.03585364 -0.0615214  -0.08034763\n",
      " -0.00310868 -0.05625383  0.22768656 -0.03078396 -0.00093711  0.07541776\n",
      " -0.07539921 -0.00093711 -0.00093711 -0.13380037 -0.02287808  0.14030092\n",
      " -0.00093711  0.0675746  -0.02287808 -0.06194408 -0.00093711  0.11158905\n",
      " -0.1115793  -0.00093711 -0.03883712  0.34977278 -0.00985026 -0.06809758\n",
      " -0.05639721 -0.01700588 -0.1043895  -0.04866994 -0.01884734 -0.01755426\n",
      " -0.00093711 -0.07154988  0.28459295 -0.07566808 -0.07245777 -0.07231755\n",
      " -0.00093711 -0.05032896  0.05894915 -0.02741112 -0.08312104  0.0289512\n",
      " -0.05192644 -0.28034922 -0.35098632  0.29132651 -0.23436601 -0.18535758]: \n",
      "Norm = 1.0\n",
      "Fold 1\tTrain number: 22240 Validation number: 2472\n",
      "Fold 2\tTrain number: 22240 Validation number: 2472\n",
      "Fold 3\tTrain number: 22240 Validation number: 2472\n",
      "Fold 4\tTrain number: 22240 Validation number: 2472\n",
      "Fold 5\tTrain number: 22241 Validation number: 2471\n",
      "Fold 6\tTrain number: 22241 Validation number: 2471\n",
      "Fold 7\tTrain number: 22241 Validation number: 2471\n",
      "Fold 8\tTrain number: 22241 Validation number: 2471\n",
      "Fold 9\tTrain number: 22242 Validation number: 2470\n",
      "Fold 10\tTrain number: 22242 Validation number: 2470\n"
     ]
    }
   ],
   "source": [
    "train_input = np.hstack((np.array(train_input_raw)[:,0:1], \n",
    "                         train_text_ohe_vectors[:,0:train_text_ohe_vectors.shape[1]], \n",
    "                         np.array(train_input_raw)[:,10:13],\n",
    "                         np.array(train_input_raw)[:,14:]\n",
    "                        )).astype(float)\n",
    "train_input = mean_reduce.fit_transform(train_input)\n",
    "print(train_input.shape)\n",
    "print('Vector = {0}: \\nNorm = {1}'.format(train_input[0], np.linalg.norm(train_input[0])))\n",
    "\n",
    "train_input = normalize(train_input)\n",
    "print(train_input.shape)\n",
    "print('Vector = {0}: \\nNorm = {1}'.format(train_input[0], np.linalg.norm(train_input[0])))\n",
    "\n",
    "folds = []\n",
    "for tr_split, va_split in skf.split(train_input, train_output):\n",
    "    folds.append((tr_split, va_split))\n",
    "for i in range(0, len(folds)):\n",
    "    print(\"Fold {0}\\tTrain number: {1} Validation number: {2}\".format(i+1, len(folds[i][0]), len(folds[i][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 4: SVM with Gaussian Kernel with 10 fold cross validation on modified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing fold 1\n",
      "Performing fold 2\n",
      "Performing fold 3\n",
      "Performing fold 4\n",
      "Performing fold 5\n",
      "Performing fold 6\n",
      "Performing fold 7\n",
      "Performing fold 8\n",
      "Performing fold 9\n",
      "Performing fold 10\n",
      "Average training accuracy after 10 fold cross validation = 0.8958310813750568\n",
      "Average training precision after 10 fold cross validation = 0.6276384745715521\n",
      "Average training recall after 10 fold cross validation = 0.18522490533697172\n",
      "Average training AUC-ROC after 10 fold cross validation = 0.5856376058714079\n",
      "Average validation accuracy after 10 fold cross validation = 0.8957588377629966\n",
      "Average validation precision after 10 fold cross validation = 0.6243785231528323\n",
      "Average validation recall after 10 fold cross validation = 0.18497073309094658\n",
      "Average validation AUC-ROC after 10 fold cross validation = 0.5854851984592266\n"
     ]
    }
   ],
   "source": [
    "accu_train = prec_train = rcll_train = auc_train = 0.0\n",
    "accu_valid = prec_valid = rcll_valid = auc_valid = 0.0\n",
    "g_svm = SVC(kernel='rbf', cache_size=2000)\n",
    "for i in range(0, len(folds)):\n",
    "    print(\"Performing fold {0}\".format(i+1))\n",
    "    g_svm.fit(train_input[folds[i][0]], train_output[folds[i][0]])\n",
    "\n",
    "    train_pred = g_svm.predict(train_input[folds[i][0]])\n",
    "    valid_pred = g_svm.predict(train_input[folds[i][1]])\n",
    "\n",
    "    accu_train += accuracy_score(train_output[folds[i][0]], train_pred)\n",
    "    prec_train += precision_score(train_output[folds[i][0]], train_pred)\n",
    "    rcll_train += recall_score(train_output[folds[i][0]], train_pred)\n",
    "    auc_train += roc_auc_score(train_output[folds[i][0]], train_pred)\n",
    "    \n",
    "    accu_valid += accuracy_score(train_output[folds[i][1]], valid_pred)\n",
    "    prec_valid += precision_score(train_output[folds[i][1]], valid_pred)\n",
    "    rcll_valid += recall_score(train_output[folds[i][1]], valid_pred)\n",
    "    auc_valid += roc_auc_score(train_output[folds[i][1]], valid_pred)\n",
    "    \n",
    "print(\"Average training accuracy after 10 fold cross validation = {0}\".format(accu_train/len(folds)))\n",
    "print(\"Average training precision after 10 fold cross validation = {0}\".format(prec_train/len(folds)))\n",
    "print(\"Average training recall after 10 fold cross validation = {0}\".format(rcll_train/len(folds)))\n",
    "print(\"Average training AUC-ROC after 10 fold cross validation = {0}\".format(auc_train/len(folds)))\n",
    "\n",
    "print(\"Average validation accuracy after 10 fold cross validation = {0}\".format(accu_valid/len(folds)))\n",
    "print(\"Average validation precision after 10 fold cross validation = {0}\".format(prec_valid/len(folds)))\n",
    "print(\"Average validation recall after 10 fold cross validation = {0}\".format(rcll_valid/len(folds)))\n",
    "print(\"Average validation AUC-ROC after 10 fold cross validation = {0}\".format(auc_valid/len(folds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 5: Random Forests with multiple number of trees and 10 fold cross validation and modified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training accuracy after 10 fold cross validation = 0.9694885181258893 for m = 3\n",
      "Average training precision after 10 fold cross validation = 0.9096471722958366 for m = 3\n",
      "Average training recall after 10 fold cross validation = 0.8095869553789468 for m = 3\n",
      "\n",
      "Average training AUC-ROC after 10 fold cross validation = 0.8996883887161916 for m = 3\n",
      "\n",
      "Average validation accuracy after 10 fold cross validation = 0.8698199186424318 for m = 3\n",
      "Average validation precision after 10 fold cross validation = 0.3924645475716879 for m = 3\n",
      "Average validation recall after 10 fold cross validation = 0.28087594440576574 for m = 3\n",
      "\n",
      "Average validation AUC-ROC after 10 fold cross validation = 0.6127336038743258 for m = 3\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9638771925156228 for m = 4\n",
      "Average training precision after 10 fold cross validation = 0.9646295432446712 for m = 4\n",
      "Average training recall after 10 fold cross validation = 0.7052197122116501 for m = 4\n",
      "\n",
      "Average training AUC-ROC after 10 fold cross validation = 0.8509681204626265 for m = 4\n",
      "\n",
      "Average validation accuracy after 10 fold cross validation = 0.8852380747576065 for m = 4\n",
      "Average validation precision after 10 fold cross validation = 0.4804916100841881 for m = 4\n",
      "Average validation recall after 10 fold cross validation = 0.2032889817178515 for m = 4\n",
      "\n",
      "Average validation AUC-ROC after 10 fold cross validation = 0.5875530490284167 for m = 4\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9786203626293574 for m = 5\n",
      "Average training precision after 10 fold cross validation = 0.9504651871191859 for m = 5\n",
      "Average training recall after 10 fold cross validation = 0.8548049153090467 for m = 5\n",
      "\n",
      "Average training AUC-ROC after 10 fold cross validation = 0.924572486761307 for m = 5\n",
      "\n",
      "Average validation accuracy after 10 fold cross validation = 0.8771456096675075 for m = 5\n",
      "Average validation precision after 10 fold cross validation = 0.4287690286059897 for m = 5\n",
      "Average validation recall after 10 fold cross validation = 0.2661522394987236 for m = 5\n",
      "\n",
      "Average validation AUC-ROC after 10 fold cross validation = 0.6104341430384601 for m = 5\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9734586845843562 for m = 6\n",
      "Average training precision after 10 fold cross validation = 0.9755761696624367 for m = 6\n",
      "Average training recall after 10 fold cross validation = 0.7840434215368146 for m = 6\n",
      "\n",
      "Average training AUC-ROC after 10 fold cross validation = 0.8907752050818424 for m = 6\n",
      "\n",
      "Average validation accuracy after 10 fold cross validation = 0.8843484018535189 for m = 6\n",
      "Average validation precision after 10 fold cross validation = 0.47116608438238483 for m = 6\n",
      "Average validation recall after 10 fold cross validation = 0.21013124983883863 for m = 6\n",
      "\n",
      "Average validation AUC-ROC after 10 fold cross validation = 0.590039369764497 for m = 6\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9831660765397124 for m = 7\n",
      "Average training precision after 10 fold cross validation = 0.9682838291516497 for m = 7\n",
      "Average training recall after 10 fold cross validation = 0.879389935213372 for m = 7\n",
      "\n",
      "Average training AUC-ROC after 10 fold cross validation = 0.9378657504941319 for m = 7\n",
      "\n",
      "Average validation accuracy after 10 fold cross validation = 0.8815953985031975 for m = 7\n",
      "Average validation precision after 10 fold cross validation = 0.45630150587789037 for m = 7\n",
      "Average validation recall after 10 fold cross validation = 0.26721977256904156 for m = 7\n",
      "\n",
      "Average validation AUC-ROC after 10 fold cross validation = 0.6134073964445854 for m = 7\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9785034654539422 for m = 8\n",
      "Average training precision after 10 fold cross validation = 0.9786980849959186 for m = 8\n",
      "Average training recall after 10 fold cross validation = 0.8271869190589293 for m = 8\n",
      "\n",
      "Average training AUC-ROC after 10 fold cross validation = 0.9124508313600505 for m = 8\n",
      "\n",
      "Average validation accuracy after 10 fold cross validation = 0.8855214591564202 for m = 8\n",
      "Average validation precision after 10 fold cross validation = 0.4824931911282941 for m = 8\n",
      "Average validation recall after 10 fold cross validation = 0.2205255150718135 for m = 8\n",
      "\n",
      "Average validation AUC-ROC after 10 fold cross validation = 0.595236460775478 for m = 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in range(3, 9):\n",
    "    rnd_frst = RandomForestClassifier(n_estimators = m)\n",
    "    accu_train = prec_train = rcll_train = auc_train = 0.0\n",
    "    accu_valid = prec_valid = rcll_valid = auc_valid = 0.0\n",
    "    for i in range(0, len(folds)):\n",
    "        rnd_frst.fit(train_input[folds[i][0]], train_output[folds[i][0]])\n",
    "\n",
    "        train_pred = rnd_frst.predict(train_input[folds[i][0]])\n",
    "        valid_pred = rnd_frst.predict(train_input[folds[i][1]])\n",
    "\n",
    "        accu_train += accuracy_score(train_output[folds[i][0]], train_pred)\n",
    "        prec_train += precision_score(train_output[folds[i][0]], train_pred)\n",
    "        rcll_train += recall_score(train_output[folds[i][0]], train_pred)\n",
    "        auc_train += roc_auc_score(train_output[folds[i][0]], train_pred)\n",
    "    \n",
    "        accu_valid += accuracy_score(train_output[folds[i][1]], valid_pred)\n",
    "        prec_valid += precision_score(train_output[folds[i][1]], valid_pred)\n",
    "        rcll_valid += recall_score(train_output[folds[i][1]], valid_pred)\n",
    "        auc_valid += roc_auc_score(train_output[folds[i][1]], valid_pred)\n",
    "    \n",
    "    print(\"Average training accuracy after 10 fold cross validation = {0} for m = {1}\".format(accu_train/len(folds), m))\n",
    "    print(\"Average training precision after 10 fold cross validation = {0} for m = {1}\".format(prec_train/len(folds), m))\n",
    "    print(\"Average training recall after 10 fold cross validation = {0} for m = {1}\\n\".format(rcll_train/len(folds), m))\n",
    "    print(\"Average training AUC-ROC after 10 fold cross validation = {0} for m = {1}\\n\".format(auc_train/len(folds), m))\n",
    "\n",
    "    print(\"Average validation accuracy after 10 fold cross validation = {0} for m = {1}\".format(accu_valid/len(folds), m))\n",
    "    print(\"Average validation precision after 10 fold cross validation = {0} for m = {1}\".format(prec_valid/len(folds), m))\n",
    "    print(\"Average validation recall after 10 fold cross validation = {0} for m = {1}\\n\".format(rcll_valid/len(folds), m))\n",
    "    print(\"Average validation AUC-ROC after 10 fold cross validation = {0} for m = {1}\\n\".format(auc_valid/len(folds), m))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 6: AdaBoost with multiple weak classifiers and 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training accuracy after 10 fold cross validation = 0.9826580070722413 for t = 10\n",
      "Average training precision after 10 fold cross validation = 0.9823910636246657 for t = 10\n",
      "Average training recall after 10 fold cross validation = 0.8615107852929416 for t = 10\n",
      "\n",
      "Average training AUC-ROC after 10 fold cross validation = 0.9297749117888896 for t = 10\n",
      "\n",
      "Average validation accuracy after 10 fold cross validation = 0.8853998214382417 for t = 10\n",
      "Average validation precision after 10 fold cross validation = 0.48157310542870624 for t = 10\n",
      "Average validation recall after 10 fold cross validation = 0.21982671926974548 for t = 10\n",
      "\n",
      "Average validation AUC-ROC after 10 fold cross validation = 0.5948641382403228 for t = 10\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.993678287210772 for t = 25\n",
      "Average training precision after 10 fold cross validation = 0.9906729963843015 for t = 25\n",
      "Average training recall after 10 fold cross validation = 0.952865681247242 for t = 25\n",
      "\n",
      "Average training AUC-ROC after 10 fold cross validation = 0.975862794735917 for t = 25\n",
      "\n",
      "Average validation accuracy after 10 fold cross validation = 0.8866140033237407 for t = 25\n",
      "Average validation precision after 10 fold cross validation = 0.49470548724485164 for t = 25\n",
      "Average validation recall after 10 fold cross validation = 0.2510610866145793 for t = 25\n",
      "\n",
      "Average validation AUC-ROC after 10 fold cross validation = 0.6091817635135863 for t = 25\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9955891907092029 for t = 50\n",
      "Average training precision after 10 fold cross validation = 0.9920726437533671 for t = 50\n",
      "Average training recall after 10 fold cross validation = 0.968590353212171 for t = 50\n",
      "\n",
      "Average training AUC-ROC after 10 fold cross validation = 0.9838036700984467 for t = 50\n",
      "\n",
      "Average validation accuracy after 10 fold cross validation = 0.889082148289841 for t = 50\n",
      "Average validation precision after 10 fold cross validation = 0.518449670948035 for t = 50\n",
      "Average validation recall after 10 fold cross validation = 0.24747170005930735 for t = 50\n",
      "\n",
      "Average validation AUC-ROC after 10 fold cross validation = 0.6090059092925373 for t = 50\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9964209928956091 for t = 100\n",
      "Average training precision after 10 fold cross validation = 0.9942155150315761 for t = 100\n",
      "Average training recall after 10 fold cross validation = 0.973898460063114 for t = 100\n",
      "\n",
      "Average training AUC-ROC after 10 fold cross validation = 0.9865894668427957 for t = 100\n",
      "\n",
      "Average validation accuracy after 10 fold cross validation = 0.8892442881560901 for t = 100\n",
      "Average validation precision after 10 fold cross validation = 0.5193050740098357 for t = 100\n",
      "Average validation recall after 10 fold cross validation = 0.2442420257342513 for t = 100\n",
      "\n",
      "Average validation AUC-ROC after 10 fold cross validation = 0.607687563371218 for t = 100\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9965064215178672 for t = 200\n",
      "Average training precision after 10 fold cross validation = 0.9954300048807969 for t = 200\n",
      "Average training recall after 10 fold cross validation = 0.9734594179557883 for t = 200\n",
      "\n",
      "Average training AUC-ROC after 10 fold cross validation = 0.9864459521128905 for t = 200\n",
      "\n",
      "Average validation accuracy after 10 fold cross validation = 0.8894060513404201 for t = 200\n",
      "Average validation precision after 10 fold cross validation = 0.5210750284629636 for t = 200\n",
      "Average validation recall after 10 fold cross validation = 0.24567700678167145 for t = 200\n",
      "\n",
      "Average validation AUC-ROC after 10 fold cross validation = 0.6084050746976813 for t = 200\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9965019255193057 for t = 250\n",
      "Average training precision after 10 fold cross validation = 0.9954728526009593 for t = 250\n",
      "Average training recall after 10 fold cross validation = 0.9733795298469303 for t = 250\n",
      "\n",
      "Average training AUC-ROC after 10 fold cross validation = 0.9864085420133802 for t = 250\n",
      "\n",
      "Average validation accuracy after 10 fold cross validation = 0.8889608054906988 for t = 250\n",
      "Average validation precision after 10 fold cross validation = 0.5167212514047028 for t = 250\n",
      "Average validation recall after 10 fold cross validation = 0.24747427864160287 for t = 250\n",
      "\n",
      "Average validation AUC-ROC after 10 fold cross validation = 0.6089387783281273 for t = 250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in [10, 25, 50, 100, 200, 250, 500, 1000]:\n",
    "    rnd_frst = RandomForestClassifier(n_estimators = t)\n",
    "    accu_train = prec_train = rcll_train = auc_train = 0.0\n",
    "    accu_valid = prec_valid = rcll_valid = auc_valid = 0.0\n",
    "    for i in range(0, len(folds)):\n",
    "        rnd_frst.fit(train_input[folds[i][0]], train_output[folds[i][0]])\n",
    "\n",
    "        train_pred = rnd_frst.predict(train_input[folds[i][0]])\n",
    "        valid_pred = rnd_frst.predict(train_input[folds[i][1]])\n",
    "\n",
    "        accu_train += accuracy_score(train_output[folds[i][0]], train_pred)\n",
    "        prec_train += precision_score(train_output[folds[i][0]], train_pred)\n",
    "        rcll_train += recall_score(train_output[folds[i][0]], train_pred)\n",
    "        auc_train += roc_auc_score(train_output[folds[i][0]], train_pred)\n",
    "    \n",
    "        accu_valid += accuracy_score(train_output[folds[i][1]], valid_pred)\n",
    "        prec_valid += precision_score(train_output[folds[i][1]], valid_pred)\n",
    "        rcll_valid += recall_score(train_output[folds[i][1]], valid_pred)\n",
    "        auc_valid += roc_auc_score(train_output[folds[i][1]], valid_pred)\n",
    "    \n",
    "    print(\"Average training accuracy after 10 fold cross validation = {0} for t = {1}\".format(accu_train/len(folds), t))\n",
    "    print(\"Average training precision after 10 fold cross validation = {0} for t = {1}\".format(prec_train/len(folds), t))\n",
    "    print(\"Average training recall after 10 fold cross validation = {0} for t = {1}\\n\".format(rcll_train/len(folds), t))\n",
    "    print(\"Average training AUC-ROC after 10 fold cross validation = {0} for t = {1}\\n\".format(auc_train/len(folds), t))\n",
    "\n",
    "    print(\"Average validation accuracy after 10 fold cross validation = {0} for t = {1}\".format(accu_valid/len(folds), t))\n",
    "    print(\"Average validation precision after 10 fold cross validation = {0} for t = {1}\".format(prec_valid/len(folds), t))\n",
    "    print(\"Average validation recall after 10 fold cross validation = {0} for t = {1}\\n\".format(rcll_valid/len(folds), t))\n",
    "    print(\"Average validation AUC-ROC after 10 fold cross validation = {0} for t = {1}\\n\".format(auc_valid/len(folds), t))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
