{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24712 20\n"
     ]
    }
   ],
   "source": [
    "# Data Processing\n",
    "import numpy as np\n",
    "\n",
    "train_data = np.genfromtxt('trainData.csv', delimiter=',', dtype=str)\n",
    "m = train_data.shape[0] - 1\n",
    "d = train_data.shape[1]\n",
    "print(m, d)\n",
    "train_input, train_output = train_data[1:,0:d-1].tolist(), train_data[1:,d-1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above step uses `numpy`'s `genfromtxt` function since there are no missing values. Below I randomly print to get the actual types of data like textual information and specific fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['28', '\"admin.\"', '\"single\"', '\"university.degree\"', '\"no\"', '\"yes\"', '\"no\"', '\"cellular\"', '\"aug\"', '\"mon\"', '1', '999', '0', '\"nonexistent\"', '-2.9', '92.201', '-31.4', '0.861', '5076.2'], '1']\n"
     ]
    }
   ],
   "source": [
    "print([train_input[0], train_output[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing step 1: \n",
    "Remove quotes in textual information\n",
    "\n",
    "#### Preprocessing step 2:\n",
    "Convert numeric information to numbers as opposed to within single quotes. These fields are `0, 10, 11, 12, 14, ..., 19`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.0, 'admin.', 'single', 'university.degree', 'no', 'yes', 'no', 'cellular', 'aug', 'mon', 1.0, 999.0, 0.0, 'nonexistent', -2.9, 92.201, -31.4, 0.861, 5076.2]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, m-1):\n",
    "    for j in range(0, d-1):\n",
    "        if train_input[i][j].find(\"\\\"\") != -1:\n",
    "            train_input[i][j] = train_input[i][j][1:-1] # removing double quotes in pairs\n",
    "        else:\n",
    "            train_input[i][j] = float(train_input[i][j])\n",
    "    train_output[i] = float(train_output[i])\n",
    "train_output = np.array(train_output).astype(float)\n",
    "\n",
    "print(train_input[0])\n",
    "print(train_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the preprocessing has been completed, it is time to separate the input and outputs and begin training. Clearly, we might have to go with Ensemble methods since the data has both textual and numeric information in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53.0, 'management', 'divorced', 'university.degree', 'no', 'no', 'no', 'telephone', 'jun', 'fri', 3.0, 999.0, 0.0, 'nonexistent', 1.4, 94.465, -41.8, 4.959, 5228.1]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "rand_index = np.random.randint(low=0, high=m)\n",
    "print(train_input[rand_index])\n",
    "print(train_output[rand_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the data through a simple level of preprocessing, I am going to convert text data into numeric values. For this I am first going to tokenize and then merge this into the actual training input.\n",
    "\n",
    "#### Preprocessing step 3:\n",
    "Convert the text data into numbers using `LabelEncoder`.\n",
    "\n",
    "#### Preprocessing step 4:\n",
    "Normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training text data : (24712, 10)\n",
      "Size of training text data: (24712, 10)\n",
      "Text: ['admin.' 'single' 'university.degree' 'no' 'yes' 'no' 'cellular' 'aug'\n",
      " 'mon' 'nonexistent'] --> Data: [1 3 7 1 3 1 1 2 2 2]\n",
      "Text: ['blue-collar' 'single' 'basic.9y' 'no' 'yes' 'no' 'cellular' 'jul' 'tue'\n",
      " 'nonexistent'] --> Data: [2 3 3 1 3 1 1 4 4 2]\n"
     ]
    }
   ],
   "source": [
    "train_text_data = np.hstack((np.array(train_input)[:,1:10], np.array(train_input)[:,13:14]))\n",
    "print('Size of training text data : {0}'.format(train_text_data.shape))\n",
    "\n",
    "# Converting the textual data into one vector per training input\n",
    "train_text_vectors = []\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, normalize, StandardScaler\n",
    "\n",
    "for j in range(0, train_text_data.shape[1]):\n",
    "    lbl_enc = LabelEncoder()\n",
    "    train_text_vectors.append(lbl_enc.fit_transform(train_text_data[:,j]))\n",
    "train_text_vectors = np.array(train_text_vectors).T\n",
    "\n",
    "print('Size of training text data: {0}'.format(train_text_vectors.shape))\n",
    "print('Text: {0} --> Data: {1}'.format(train_text_data[0], train_text_vectors[0]))\n",
    "print('Text: {0} --> Data: {1}'.format(train_text_data[10], train_text_vectors[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24712, 19)\n",
      "Vector = [-1.1518788  -1.04245572  1.36067936  1.05600834 -0.51164653  0.94134947\n",
      " -0.44949276 -0.75723938 -1.38470179 -0.70956021 -0.56425354  0.19653049\n",
      " -0.35249416  0.19500115 -1.90310477 -2.38261316  1.97762226 -1.5909553\n",
      " -1.25826956]: \n",
      "Norm = 5.250495168763574\n",
      "(24712, 19)\n",
      "Vector = [-0.21938479 -0.19854427  0.25915258  0.20112548 -0.09744729  0.17928775\n",
      " -0.08560959 -0.14422247 -0.26372785 -0.13514158 -0.10746673  0.03743085\n",
      " -0.06713541  0.03713957 -0.36246196 -0.45378828  0.37665443 -0.30301052\n",
      " -0.23964779]: \n",
      "Norm = 1.0\n"
     ]
    }
   ],
   "source": [
    "train_input = np.hstack((np.array(train_input)[:,0:1], \n",
    "                         train_text_vectors[:,0:train_text_vectors.shape[1] - 1], \n",
    "                         np.array(train_input)[:,10:13],\n",
    "                         train_text_vectors[:,train_text_vectors.shape[1] - 1].reshape(-1, 1),\n",
    "                         np.array(train_input)[:,14:]\n",
    "                        )).astype(float)\n",
    "mean_reduce = StandardScaler()\n",
    "train_input = mean_reduce.fit_transform(train_input)\n",
    "print(train_input.shape)\n",
    "print('Vector = {0}: \\nNorm = {1}'.format(train_input[0], np.linalg.norm(train_input[0])))\n",
    "\n",
    "train_input = normalize(train_input)\n",
    "print(train_input.shape)\n",
    "print('Vector = {0}: \\nNorm = {1}'.format(train_input[0], np.linalg.norm(train_input[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the preprocessing steps are completed. I will try my preprocessed dataset on multiple methods of classification.\n",
    "For this, I will generate 10 folds (stratified) and use 10-fold cross validation to get the best method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\tTrain number: 22240 Validation number: 2472\n",
      "Fold 2\tTrain number: 22240 Validation number: 2472\n",
      "Fold 3\tTrain number: 22240 Validation number: 2472\n",
      "Fold 4\tTrain number: 22240 Validation number: 2472\n",
      "Fold 5\tTrain number: 22241 Validation number: 2471\n",
      "Fold 6\tTrain number: 22241 Validation number: 2471\n",
      "Fold 7\tTrain number: 22241 Validation number: 2471\n",
      "Fold 8\tTrain number: 22241 Validation number: 2471\n",
      "Fold 9\tTrain number: 22242 Validation number: 2470\n",
      "Fold 10\tTrain number: 22242 Validation number: 2470\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "folds = []\n",
    "for tr_split, va_split in skf.split(train_input, train_output):\n",
    "    folds.append((tr_split, va_split))\n",
    "for i in range(0, len(folds)):\n",
    "    print(\"Fold {0}\\tTrain number: {1} Validation number: {2}\".format(i+1, len(folds[i][0]), len(folds[i][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1: SVM with Gaussian Kernel with 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing fold 1\n",
      "Performing fold 2\n",
      "Performing fold 3\n",
      "Performing fold 4\n",
      "Performing fold 5\n",
      "Performing fold 6\n",
      "Performing fold 7\n",
      "Performing fold 8\n",
      "Performing fold 9\n",
      "Performing fold 10\n",
      "Average training accuracy after 10 fold cross validation = 0.8958805519146763\n",
      "Average training precision after 10 fold cross validation = 0.6148393596168257\n",
      "Average training recall after 10 fold cross validation = 0.20294544191744207\n",
      "Average validation accuracy after 10 fold cross validation = 0.8958811959569284\n",
      "Average validation precision after 10 fold cross validation = 0.6184453796596394\n",
      "Average validation recall after 10 fold cross validation = 0.2029486088548516\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "accu_train = prec_train = rcll_train = 0.0\n",
    "accu_valid = prec_valid = rcll_valid = 0.0\n",
    "g_svm = SVC(kernel='rbf', cache_size=2000)\n",
    "for i in range(0, len(folds)):\n",
    "    print(\"Performing fold {0}\".format(i+1))\n",
    "    g_svm.fit(train_input[folds[i][0]], train_output[folds[i][0]])\n",
    "\n",
    "    train_pred = g_svm.predict(train_input[folds[i][0]])\n",
    "    valid_pred = g_svm.predict(train_input[folds[i][1]])\n",
    "\n",
    "    accu_train += accuracy_score(train_output[folds[i][0]], train_pred)\n",
    "    prec_train += precision_score(train_output[folds[i][0]], train_pred)\n",
    "    rcll_train += recall_score(train_output[folds[i][0]], train_pred)\n",
    "    \n",
    "    accu_valid += accuracy_score(train_output[folds[i][1]], valid_pred)\n",
    "    prec_valid += precision_score(train_output[folds[i][1]], valid_pred)\n",
    "    rcll_valid += recall_score(train_output[folds[i][1]], valid_pred)\n",
    "    \n",
    "print(\"Average training accuracy after 10 fold cross validation = {0}\".format(accu_train/len(folds)))\n",
    "print(\"Average training precision after 10 fold cross validation = {0}\".format(prec_train/len(folds)))\n",
    "print(\"Average training recall after 10 fold cross validation = {0}\".format(rcll_train/len(folds)))\n",
    "\n",
    "print(\"Average validation accuracy after 10 fold cross validation = {0}\".format(accu_valid/len(folds)))\n",
    "print(\"Average validation precision after 10 fold cross validation = {0}\".format(prec_valid/len(folds)))\n",
    "print(\"Average validation recall after 10 fold cross validation = {0}\".format(rcll_valid/len(folds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2: Random Forests with multiple number of trees and 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training accuracy after 10 fold cross validation = 0.9704237076585225 for m = 3\n",
      "Average training precision after 10 fold cross validation = 0.9102265945253913 for m = 3\n",
      "Average training recall after 10 fold cross validation = 0.8181666674631585 for m = 3\n",
      "Average validation accuracy after 10 fold cross validation = 0.8704685107436507 for m = 3\n",
      "Average validation precision after 10 fold cross validation = 0.3956610189833982 for m = 3\n",
      "Average validation recall after 10 fold cross validation = 0.28160439390423153 for m = 3\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9645831190743366 for m = 4\n",
      "Average training precision after 10 fold cross validation = 0.9656396595876655 for m = 4\n",
      "Average training recall after 10 fold cross validation = 0.7109277852913487 for m = 4\n",
      "Average validation accuracy after 10 fold cross validation = 0.8864926111460741 for m = 4\n",
      "Average validation precision after 10 fold cross validation = 0.4917565623870731 for m = 4\n",
      "Average validation recall after 10 fold cross validation = 0.2047355663856012 for m = 4\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9788991315209191 for m = 5\n",
      "Average training precision after 10 fold cross validation = 0.9563866891801375 for m = 5\n",
      "Average training recall after 10 fold cross validation = 0.8515323064963448 for m = 5\n",
      "Average validation accuracy after 10 fold cross validation = 0.8785612215200777 for m = 5\n",
      "Average validation precision after 10 fold cross validation = 0.44061700863350295 for m = 5\n",
      "Average validation recall after 10 fold cross validation = 0.2830380856605038 for m = 5\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9741061415307632 for m = 6\n",
      "Average training precision after 10 fold cross validation = 0.9760850024342087 for m = 6\n",
      "Average training recall after 10 fold cross validation = 0.7895114161142998 for m = 6\n",
      "Average validation accuracy after 10 fold cross validation = 0.8864120819442458 for m = 6\n",
      "Average validation precision after 10 fold cross validation = 0.49253697922405804 for m = 6\n",
      "Average validation recall after 10 fold cross validation = 0.22447590314844898 for m = 6\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9835797383268018 for m = 7\n",
      "Average training precision after 10 fold cross validation = 0.9697042569170125 for m = 7\n",
      "Average training recall after 10 fold cross validation = 0.8818253039013753 for m = 7\n",
      "Average validation accuracy after 10 fold cross validation = 0.882810710116311 for m = 7\n",
      "Average validation precision after 10 fold cross validation = 0.4660648979145665 for m = 7\n",
      "Average validation recall after 10 fold cross validation = 0.2672571620123257 for m = 7\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9789575813217397 for m = 8\n",
      "Average training precision after 10 fold cross validation = 0.9800453781250587 for m = 8\n",
      "Average training recall after 10 fold cross validation = 0.830140166594186 for m = 8\n",
      "Average validation accuracy after 10 fold cross validation = 0.887666732930658 for m = 8\n",
      "Average validation precision after 10 fold cross validation = 0.5048303970725968 for m = 8\n",
      "Average validation recall after 10 fold cross validation = 0.234558159923674 for m = 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for m in range(3, 9):\n",
    "    rnd_frst = RandomForestClassifier(n_estimators = m)\n",
    "    accu_train = prec_train = rcll_train = 0.0\n",
    "    accu_valid = prec_valid = rcll_valid = 0.0\n",
    "    for i in range(0, len(folds)):\n",
    "        rnd_frst.fit(train_input[folds[i][0]], train_output[folds[i][0]])\n",
    "\n",
    "        train_pred = rnd_frst.predict(train_input[folds[i][0]])\n",
    "        valid_pred = rnd_frst.predict(train_input[folds[i][1]])\n",
    "\n",
    "        accu_train += accuracy_score(train_output[folds[i][0]], train_pred)\n",
    "        prec_train += precision_score(train_output[folds[i][0]], train_pred)\n",
    "        rcll_train += recall_score(train_output[folds[i][0]], train_pred)\n",
    "    \n",
    "        accu_valid += accuracy_score(train_output[folds[i][1]], valid_pred)\n",
    "        prec_valid += precision_score(train_output[folds[i][1]], valid_pred)\n",
    "        rcll_valid += recall_score(train_output[folds[i][1]], valid_pred)\n",
    "    \n",
    "    print(\"Average training accuracy after 10 fold cross validation = {0} for m = {1}\".format(accu_train/len(folds), m))\n",
    "    print(\"Average training precision after 10 fold cross validation = {0} for m = {1}\".format(prec_train/len(folds), m))\n",
    "    print(\"Average training recall after 10 fold cross validation = {0} for m = {1}\".format(rcll_train/len(folds), m))\n",
    "\n",
    "    print(\"Average validation accuracy after 10 fold cross validation = {0} for m = {1}\".format(accu_valid/len(folds), m))\n",
    "    print(\"Average validation precision after 10 fold cross validation = {0} for m = {1}\".format(prec_valid/len(folds), m))\n",
    "    print(\"Average validation recall after 10 fold cross validation = {0} for m = {1}\\n\".format(rcll_valid/len(folds), m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 3: AdaBoost with multiple weak classifiers and 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training accuracy after 10 fold cross validation = 0.8986187557383187 for t = 10\n",
      "Average training precision after 10 fold cross validation = 0.6718016025616685 for t = 10\n",
      "Average training recall after 10 fold cross validation = 0.19683875664473133 for t = 10\n",
      "Average validation accuracy after 10 fold cross validation = 0.8979448922597184 for t = 10\n",
      "Average validation precision after 10 fold cross validation = 0.6594612902374594 for t = 10\n",
      "Average validation recall after 10 fold cross validation = 0.19648926020473945 for t = 10\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.8986861981425639 for t = 25\n",
      "Average training precision after 10 fold cross validation = 0.6575265242220661 for t = 25\n",
      "Average training recall after 10 fold cross validation = 0.21040864798734535 for t = 25\n",
      "Average validation accuracy after 10 fold cross validation = 0.8973379324053521 for t = 25\n",
      "Average validation precision after 10 fold cross validation = 0.6391766417150258 for t = 25\n",
      "Average validation recall after 10 fold cross validation = 0.205109460818442 for t = 25\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.8996933646907394 for t = 50\n",
      "Average training precision after 10 fold cross validation = 0.6695724358211261 for t = 50\n",
      "Average training recall after 10 fold cross validation = 0.2167143765143297 for t = 50\n",
      "Average validation accuracy after 10 fold cross validation = 0.8981875451952688 for t = 50\n",
      "Average validation precision after 10 fold cross validation = 0.6490587525806069 for t = 50\n",
      "Average validation recall after 10 fold cross validation = 0.21264149970346305 for t = 50\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9008983541645744 for t = 100\n",
      "Average training precision after 10 fold cross validation = 0.677783238094537 for t = 100\n",
      "Average training recall after 10 fold cross validation = 0.22968514686508862 for t = 100\n",
      "Average validation accuracy after 10 fold cross validation = 0.8983492756505844 for t = 100\n",
      "Average validation precision after 10 fold cross validation = 0.6429777339283238 for t = 100\n",
      "Average validation recall after 10 fold cross validation = 0.22054485443902938 for t = 100\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9022876898894271 for t = 200\n",
      "Average training precision after 10 fold cross validation = 0.685370955368422 for t = 200\n",
      "Average training recall after 10 fold cross validation = 0.24529056810560843 for t = 200\n",
      "Average validation accuracy after 10 fold cross validation = 0.8979042427449215 for t = 200\n",
      "Average validation precision after 10 fold cross validation = 0.6338488413779687 for t = 200\n",
      "Average validation recall after 10 fold cross validation = 0.22413553028544908 for t = 200\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9026743572882335 for t = 250\n",
      "Average training precision after 10 fold cross validation = 0.6848187840697713 for t = 250\n",
      "Average training recall after 10 fold cross validation = 0.2521546053941598 for t = 250\n",
      "Average validation accuracy after 10 fold cross validation = 0.8970545644572093 for t = 250\n",
      "Average validation precision after 10 fold cross validation = 0.6195255296157673 for t = 250\n",
      "Average validation recall after 10 fold cross validation = 0.22520950981150561 for t = 250\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.904000751256923 for t = 500\n",
      "Average training precision after 10 fold cross validation = 0.6893083489857308 for t = 500\n",
      "Average training recall after 10 fold cross validation = 0.2692364034899076 for t = 500\n",
      "Average validation accuracy after 10 fold cross validation = 0.8962854320075799 for t = 500\n",
      "Average validation precision after 10 fold cross validation = 0.6027768377387779 for t = 500\n",
      "Average validation recall after 10 fold cross validation = 0.2349049792424125 for t = 500\n",
      "\n",
      "Average training accuracy after 10 fold cross validation = 0.9066175661522292 for t = 1000\n",
      "Average training precision after 10 fold cross validation = 0.7052112196801344 for t = 1000\n",
      "Average training recall after 10 fold cross validation = 0.2941011990384753 for t = 1000\n",
      "Average validation accuracy after 10 fold cross validation = 0.8957188924456096 for t = 1000\n",
      "Average validation precision after 10 fold cross validation = 0.5904707510654191 for t = 1000\n",
      "Average validation recall after 10 fold cross validation = 0.24496016090353517 for t = 1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "for t in [10, 25, 50, 100, 200, 250, 500, 1000]:\n",
    "    rnd_frst = AdaBoostClassifier(n_estimators = t)\n",
    "    accu_train = prec_train = rcll_train = 0.0\n",
    "    accu_valid = prec_valid = rcll_valid = 0.0\n",
    "    for i in range(0, len(folds)):\n",
    "        rnd_frst.fit(train_input[folds[i][0]], train_output[folds[i][0]])\n",
    "\n",
    "        train_pred = rnd_frst.predict(train_input[folds[i][0]])\n",
    "        valid_pred = rnd_frst.predict(train_input[folds[i][1]])\n",
    "\n",
    "        accu_train += accuracy_score(train_output[folds[i][0]], train_pred)\n",
    "        prec_train += precision_score(train_output[folds[i][0]], train_pred)\n",
    "        rcll_train += recall_score(train_output[folds[i][0]], train_pred)\n",
    "    \n",
    "        accu_valid += accuracy_score(train_output[folds[i][1]], valid_pred)\n",
    "        prec_valid += precision_score(train_output[folds[i][1]], valid_pred)\n",
    "        rcll_valid += recall_score(train_output[folds[i][1]], valid_pred)\n",
    "    \n",
    "    print(\"Average training accuracy after 10 fold cross validation = {0} for t = {1}\".format(accu_train/len(folds), t))\n",
    "    print(\"Average training precision after 10 fold cross validation = {0} for t = {1}\".format(prec_train/len(folds), t))\n",
    "    print(\"Average training recall after 10 fold cross validation = {0} for t = {1}\".format(rcll_train/len(folds), t))\n",
    "\n",
    "    print(\"Average validation accuracy after 10 fold cross validation = {0} for t = {1}\".format(accu_valid/len(folds), t))\n",
    "    print(\"Average validation precision after 10 fold cross validation = {0} for t = {1}\".format(prec_valid/len(folds), t))\n",
    "    print(\"Average validation recall after 10 fold cross validation = {0} for t = {1}\\n\".format(rcll_valid/len(folds), t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it seems that we are randomly trying to use multiple classifiers. I believe that there is a fundamental problem in the preprocessing. I think we have to use the `OneHotEncoder` to encode categorical data after encoding using label as shown [here](http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
